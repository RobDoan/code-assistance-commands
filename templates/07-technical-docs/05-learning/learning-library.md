# Learning Library: Our Invalidated Assumptions

> **The graveyard of bad ideas that saved us millions.**
>
> Every funeral here represents time, money, and effort not wasted.

## Our Philosophy

An invalidated hypothesis is not a failureâ€”it's a victory. This library captures our most valuable learnings: the assumptions we proved wrong before they could hurt us. We celebrate these deaths because they make us smarter.

**Motto:** "We fail fast, learn faster, and remember longest."

## How to Use This Library

- **Before starting a new experiment:** Search this library for related invalidated assumptions
- **Link from your experiment brief:** Reference relevant learnings in new `experiment-brief.md` files
- **During retrospectives:** Review recent funerals to extract patterns
- **For onboarding:** New team members should read the Hall of Fame to quickly learn what doesn't work
- **For competitive advantage:** During quarterly planning, ask "What did we learn that lets us take smart risks our competitors wouldn't?"

---

## ğŸ† Funeral Hall of Fame

*Our biggest savesâ€”hypotheses that could have cost us months or years*

### ğŸ’€ [Date] The Great [Feature Name] Funeral

**Deceased Hypothesis:** "[What we believed]"

**Cause of Death:** "[What data/insight killed it]"

**Estimated Save:** [Time/Money/Resources not wasted]

**Memorial Quote:** "[Key learning in one sentence]"

**Mourners:** [Team members involved]

**Flowers:** [Recognition/celebration done]

**Legacy:** [How this changed our approach going forward]

---

### ğŸ’€ [Date] The [Another Feature] Wake

**Deceased Hypothesis:** "[What we believed]"

**Cause of Death:** "[What data/insight killed it]"

**Estimated Save:** [Time/Money/Resources not wasted]

**Memorial Quote:** "[Key learning in one sentence]"

**Mourners:** [Team members involved]

**Flowers:** [Recognition/celebration done]

**Legacy:** [How this changed our approach going forward]

---

## ğŸ“š Learning Categories

### ğŸ¯ User Behavior Assumptions

*What we learned about how users actually behave*

| Assumption | Reality | Key Learning | Date |
|------------|---------|--------------|------|
| Users want feature X | Users ignore feature X | [Insight] | [Date] |
| Users will pay for Y | Users won't pay for Y | [Insight] | [Date] |

### ğŸ—ï¸ Technical Assumptions  

*What we learned about our architecture and systems*

| Assumption | Reality | Key Learning | Date |
|------------|---------|--------------|------|
| Technology A will scale | Technology A hits limits at X | [Insight] | [Date] |
| Integration B is simple | Integration B requires major refactor | [Insight] | [Date] |

### ğŸ’° Business Model Assumptions

*What we learned about our path to revenue*

| Assumption | Reality | Key Learning | Date |
|------------|---------|--------------|------|
| Channel C drives growth | Channel C has poor conversion | [Insight] | [Date] |
| Pricing D is optimal | Pricing D causes churn | [Insight] | [Date] |

### ğŸ¨ Design Assumptions

*What we learned about user experience and interface*

| Assumption | Reality | Key Learning | Date |
|------------|---------|--------------|------|
| UI pattern E improves UX | UI pattern E confuses users | [Insight] | [Date] |
| Flow F reduces friction | Flow F adds complexity | [Insight] | [Date] |

---

## ğŸ”„ Learning Patterns

### Recurring Themes

*What assumptions do we keep making incorrectly?*

- **Pattern 1:** [e.g., "We consistently overestimate user engagement with new features"]
- **Pattern 2:** [e.g., "We underestimate technical complexity of third-party integrations"]  
- **Pattern 3:** [e.g., "We assume users want more options when they want fewer"]

### Early Warning Signs

*How to spot similar assumptions before they become experiments*

- ğŸš© **Red Flag 1:** [Signal that suggests similar assumption might be wrong]
- ğŸš© **Red Flag 2:** [Signal that suggests similar assumption might be wrong]
- ğŸš© **Red Flag 3:** [Signal that suggests similar assumption might be wrong]

---

## ğŸ‰ Monthly Funeral Reports

### [Month Year] - Funerals Celebrated

**Total Assumptions Invalidated:** [Number]

**Estimated Time Saved:** [Hours/Days/Weeks]  

**Estimated Cost Saved:** [Dollar amount if calculable]

**Biggest Save:** [Most valuable invalidated assumption]

**Team Recognition:** [Who gets credit for biggest learning]

**New Patterns Discovered:** [Any new insights about our assumption-making]

---

## ğŸ§  Institutional Memory

### Questions We've Already Answered

*Avoid re-testing what we've already learned*

**Q:** [Question we investigated]  
**A:** [What we learned]  
**Source:** [Link to experiment that taught us this]

**Q:** [Another question we investigated]  
**A:** [What we learned]  
**Source:** [Link to experiment that taught us this]

### Zombie Assumptions  

*Ideas that keep coming back despite being invalidated*

**Zombie 1:** "[Assumption that won't die]"  

- **First Death:** [Date] - [How we killed it]
- **Resurrection:** [Date] - [How it came back]  
- **Second Death:** [Date] - [How we killed it again]
- **Prevention:** [How to stop it from coming back]

---

## ğŸ¯ Learning Velocity Metrics

### This Quarter

- **Experiments Run:** [Number]
- **Hypotheses Validated:** [Number]  
- **Hypotheses Invalidated:** [Number]
- **Learning Rate:** [Invalidated/Total - aim for 30-50%]

### Historical Trends

- **Q[X]:** [Learning rate and key insights]
- **Q[Y]:** [Learning rate and key insights]  
- **Q[Z]:** [Learning rate and key insights]

---

## ğŸ”— Learning Connections

### How Our Learnings Connect

*Map relationships between invalidated assumptions*

```
User Need A (invalidated) â†â†’ User Need B (validated)
     â†“
Technical Approach C (invalidated) â†’ Technical Approach D (validated)
     â†“  
Business Model E (testing)
```

### Cross-Pollination Opportunities

*Where learnings from one area might apply to another*

- **Learning from [Area A]** could apply to **[Area B]** because **[reasoning]**
- **Learning from [Area C]** could apply to **[Area D]** because **[reasoning]**

### Competitive Intelligence

*How our failure library becomes strategic advantage*

**Quarterly Review Question:** "What did we learn from the library last quarter that will allow us to take a smart risk our competitors wouldn't?"

Examples:

- **We learned [X] doesn't work** â†’ **So we can focus resources on [Y] while competitors waste time on [X]**
- **We discovered [Z] pattern fails** â†’ **So we can avoid similar pitfalls that will trip up others**
- **We validated [W] approach** â†’ **So we can double down while others are still experimenting**

---

## ğŸƒ Next Learning Sprints

### High-Value Questions to Answer

*What should we test next based on our learning gaps?*

1. **Question:** [What we need to learn]  
   **Risk if Wrong:** [What happens if we assume incorrectly]  
   **Test Approach:** [How we might test this]

2. **Question:** [What we need to learn]  
   **Risk if Wrong:** [What happens if we assume incorrectly]  
   **Test Approach:** [How we might test this]

---

*"The goal is not to be right; it's to get less wrong, faster."*

---

*Last Updated: [Date] | Next Funeral: [When we expect to celebrate next invalidated assumption]*
